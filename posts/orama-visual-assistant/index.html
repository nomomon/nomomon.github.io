<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/0db310923dda8a34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/0db310923dda8a34.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-59c5c889f52620d6.js" defer=""></script><script src="/_next/static/chunks/framework-50116e63224baba2.js" defer=""></script><script src="/_next/static/chunks/main-95cf1e829bcb8407.js" defer=""></script><script src="/_next/static/chunks/pages/_app-0e6b96157a72fee4.js" defer=""></script><script src="/_next/static/chunks/961-b93ac647cf18494c.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5BfileName%5D-729d3647bc712562.js" defer=""></script><script src="/_next/static/rnp_zZvOF3sbWo0tLuao-/_buildManifest.js" defer=""></script><script src="/_next/static/rnp_zZvOF3sbWo0tLuao-/_ssgManifest.js" defer=""></script></head><body><div id="__next"><article class="mt-16 min-h-full w-full max-w-screen-sm mx-auto"><h1 class="mb-8">Orama Visual Assistant</h1><div class="flex flex-row justify-between mb-8 text-gray-500"><div>Fri, Nov 8, 2019<span class="mx-1">•</span><a class="bg-gray-200 mx-1 px-1 rounded-md font-light text-sm py-1 cursor-pointer hover:text-black" href="/tags/tensorflow/">tensorflow</a><a class="bg-gray-200 mx-1 px-1 rounded-md font-light text-sm py-1 cursor-pointer hover:text-black" href="/tags/mobilenet/">mobilenet</a><a class="bg-gray-200 mx-1 px-1 rounded-md font-light text-sm py-1 cursor-pointer hover:text-black" href="/tags/react/">react</a><a class="bg-gray-200 mx-1 px-1 rounded-md font-light text-sm py-1 cursor-pointer hover:text-black" href="/tags/competition/">competition</a><a class="bg-gray-200 mx-1 px-1 rounded-md font-light text-sm py-1 cursor-pointer hover:text-black" href="/tags/project/">project</a></div><span class="underline cursor-pointer flex-end">Back</span></div><div class="markdown-body"><p>![[oramava-preview.jpeg]]</p>
</div></article><footer class="mt-16 mb-8 w-full max-w-screen-sm mx-auto"><p class="text-gray-500 text-xs">2019 - <!-- -->2023<!-- --> © </p></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"path":"public/Orama Visual Assistant.md","publish":true,"title":"Orama Visual Assistant","description":"Orama Visual Assistant is an app for visually impaired people that announces objects detected using user's phone camera.","date":"8 Nov 2019","tags":["tensorflow","mobilenet","react","competition","project"],"content":"\n![[oramava-preview.jpeg]]\n","md":"\u003cp\u003e![[oramava-preview.jpeg]]\u003c/p\u003e\n"},"__N_SSG":true},"page":"/posts/[fileName]","query":{"fileName":"orama-visual-assistant"},"buildId":"rnp_zZvOF3sbWo0tLuao-","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>