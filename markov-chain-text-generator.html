<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Markov Chain Text Generator</title><meta name="next-head-count" content="3"/><link rel="icon" href="/logo.svg"/><link rel="preload" href="/_next/static/css/060f2c5631a3598e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/060f2c5631a3598e.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-b8f8d6679aaa5f42.js" defer=""></script><script src="/_next/static/chunks/framework-cda2f1305c3d9424.js" defer=""></script><script src="/_next/static/chunks/main-f11614d8aa7ee555.js" defer=""></script><script src="/_next/static/chunks/pages/_app-891652dd44e1e4e1.js" defer=""></script><script src="/_next/static/chunks/175675d1-1434f301c5e774f6.js" defer=""></script><script src="/_next/static/chunks/9f96d65d-c9e0543547ce45e9.js" defer=""></script><script src="/_next/static/chunks/440-1dd60335387b13c8.js" defer=""></script><script src="/_next/static/chunks/998-6bb348385f3991da.js" defer=""></script><script src="/_next/static/chunks/pages/%5Bslug%5D-2b1b70858d725f5e.js" defer=""></script><script src="/_next/static/YT8lql2YkutcOkeDWDz83/_buildManifest.js" defer=""></script><script src="/_next/static/YT8lql2YkutcOkeDWDz83/_ssgManifest.js" defer=""></script></head><body><nav class="flex flex-row px-8 py-4 max-sm:px-2"><a href="/"><div class="flex flex-row items-center"><img src="/logo.svg" alt="logo" class="h-8 w-8 mr-2"/><h1 class="text-xl font-light text-gray-800">Mansur Nurmukhambetov</h1></div></a></nav><div id="__next"><div class="w-full overflow-y-auto"><div class="w-full h-64 py-20 flex flex-col items-center bg-gradient-to-r from-purple-500 to-red-500"><h1 class="text-white text-6xl drop-shadow-md">Markov Chain Text Generator</h1><p class="mb-4 text-white opacity-75 font-light">Text generator written in React.js that uses Markov chains to generate text based on a given input.</p><div class="text-white opacity-75 text-sm font-light py-1 px-4 rounded-md backdrop-blur-xl bg-black/30">August 6, 2022</div></div><article class="w-full max-w-xl m-auto mt-8 max-sm:px-4"><div class="markdown-body"><p>![[markov-chain-text.jpeg]]</p>
<p>Recently, I was reading in the Y.Practicum blog and found a <a href="https://thecode.media/markov-chain/">group of posts</a> there about Markov chains. The articles were written in a easy to understand and engaging way, and I thought it would be interesting to see for myself how the algorithm works.</p>
<p>First of all, the definition:</p>
<blockquote>
<p>Markov chains are a sequence of events or actions, where each new event depends only on the previous one and does not take into account all other events. Such an algorithm does not remember what happened before, but only looks at the previous state.</p>
</blockquote>
<p>It will be easier to understand if you look at the following example:</p>
<pre><code class="language-javascript">const dataset = [&quot;I am a human&quot;, &quot;I am a programmer&quot;, &quot;I am not a dog&quot;];
</code></pre>
<p>This dataset results in the following tree diagram:</p>
<p>![[diagram.png]]</p>
<p>In context of text generation, each word is an event. The next word is selected randomly from the words that stood after the last word. The probability of each word transition is determined by the frequency of the pair. After a random word is selected, the same thing is repeated with the sentence until the final word appears.</p>
<p>In the example from the image, after the word “a” in the source text there could be the words “programmer”, “human”, and “dog”. So, the new sentences that can be generated from the dataset are:</p>
<blockquote>
<p>I am not a programmer</p>
<p>I am not a human</p>
<p>I am a dog</p>
</blockquote>
<p>It certainly doesn&#x27;t compare to GPT-3 or Copilot, but the results are sure ridiculous.</p>
<h2>Results</h2>
<p>Example in Russian</p>
<p><img src="https://github.com/nomomon/markov-chain-text/raw/master/screenshot.png" alt="demo"/></p></div></article></div></div><footer class="w-full flex flex-row justify-center my-8"><p class="text-gray-500">Made with ❤️ by<a class="text-blue-500 hover:text-blue-700" href="https://github.com/nomomon"> nomomon</a></p></footer><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"fileName":"Markov Chain Text Generator","file":"---\ndescription: Text generator written in React.js that uses Markov chains to generate text based on a given input.\nimageURL: markov-chain-text.jpeg\ndate: Aug 6, 2022\nendDate: Aug 7, 2022\ndemo: https://nomomon.github.io/markov-chain-text/\nsource: https://github.com/nomomon/markov-chain-text\ntags: [react, node.js, nlp, markov-chain, project]\n\n---\n\n![[markov-chain-text.jpeg]]\n\nRecently, I was reading in the Y.Practicum blog and found a [group of posts](https://thecode.media/markov-chain/) there about Markov chains. The articles were written in a easy to understand and engaging way, and I thought it would be interesting to see for myself how the algorithm works.\n\nFirst of all, the definition:\n\n\u003e Markov chains are a sequence of events or actions, where each new event depends only on the previous one and does not take into account all other events. Such an algorithm does not remember what happened before, but only looks at the previous state.\n\nIt will be easier to understand if you look at the following example:\n\n```javascript\nconst dataset = [\"I am a human\", \"I am a programmer\", \"I am not a dog\"];\n```\n\nThis dataset results in the following tree diagram:\n\n![[diagram.png]]\n\nIn context of text generation, each word is an event. The next word is selected randomly from the words that stood after the last word. The probability of each word transition is determined by the frequency of the pair. After a random word is selected, the same thing is repeated with the sentence until the final word appears.\n\nIn the example from the image, after the word “a” in the source text there could be the words “programmer”, “human”, and “dog”. So, the new sentences that can be generated from the dataset are:\n\n\u003e I am not a programmer\n\u003e\n\u003e I am not a human\n\u003e\n\u003e I am a dog\n\nIt certainly doesn't compare to GPT-3 or Copilot, but the results are sure ridiculous.\n\n## Results\n\nExample in Russian\n\n![demo](https://github.com/nomomon/markov-chain-text/raw/master/screenshot.png)\n"},"__N_SSG":true},"page":"/[slug]","query":{"slug":"markov-chain-text-generator"},"buildId":"YT8lql2YkutcOkeDWDz83","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>